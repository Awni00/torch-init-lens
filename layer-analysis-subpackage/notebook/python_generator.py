"""
Python Script Generator.

This module provides the PythonScriptGenerator class for generating
Python scripts for module initialization analysis.
"""

from typing import List, Optional, Dict, Any
from pathlib import Path
import textwrap
import json

from ..config import AnalysisConfig
from ..introspection import load_module_class, merge_kwargs, validate_kwargs


class PythonScriptGenerator:
    """Generate Python scripts for module initialization analysis.

    Parameters
    ----------
    module_identifier : str
        Module identifier (e.g., "models.abstractor@RelationalAttention").
    config : AnalysisConfig
        Analysis configuration.
    module_kwargs : Optional[Dict[str, Any]]
        Additional keyword arguments for module instantiation.

    Examples
    --------
    >>> from utilities.layer_analysis import AnalysisConfig
    >>> config = AnalysisConfig(input_shape=(2, 16, 64))
    >>> generator = PythonScriptGenerator("models.abstractor@DualAttention", config)
    >>> generator.generate(Path("analysis.py"))
    """

    def __init__(
        self,
        module_identifier: str,
        config: AnalysisConfig,
        module_kwargs: Optional[Dict[str, Any]] = None,
    ):
        if "@" not in module_identifier:
            raise ValueError(
                f"Invalid module identifier: {module_identifier}. "
                "Expected format: 'module.path@ClassName'"
            )

        self.module_identifier = module_identifier
        self.config = config
        self.module_kwargs = module_kwargs or {}
        self.module_path, self.class_name = module_identifier.split("@", 1)

        self._validate_module_kwargs()

    def _validate_module_kwargs(self) -> None:
        """Validate that all required module kwargs are provided.

        Raises
        ------
        MissingModuleKwargsError
            If required kwargs are missing.
        InvalidModuleKwargsError
            If invalid kwargs are provided.
        """
        cls = load_module_class(self.module_identifier)
        input_shape = self.config.input_shape
        kwargs = merge_kwargs(cls, self.module_kwargs, input_shape)
        validate_kwargs(cls, kwargs, user_kwargs=self.module_kwargs)

    def generate(
        self,
        output_path: Path,
        skip_analyses: Optional[List[str]] = None,
    ) -> None:
        """Generate and save the Python script.

        Parameters
        ----------
        output_path : Path
            Path to save the script.
        skip_analyses : Optional[List[str]]
            Analysis types to skip.
        """
        skip_analyses = skip_analyses or []

        script_parts = [
            self._get_header(),
            self._get_imports(),
            self._get_setup(),
            self._get_module_instantiation(),
        ]

        # Add analysis sections
        analysis_map = {
            "parameter_norms": (self.config.run_parameter_norms, self._get_parameter_norms),
            "operator_norm": (self.config.run_operator_norm, self._get_operator_norm),
            "gradient_analysis": (self.config.run_gradient_analysis, self._get_gradient_analysis),
            "spectral_analysis": (self.config.run_spectral_analysis, self._get_spectral_analysis),
            "rank_analysis": (self.config.run_rank_analysis, self._get_rank_analysis),
            "lipschitz": (self.config.run_lipschitz, self._get_lipschitz),
            "activation_stats": (self.config.run_activation_stats, self._get_activation_stats),
            "gradient_ratios": (self.config.run_gradient_ratios, self._get_gradient_ratios),
            "precision_checks": (self.config.run_precision_checks, self._get_precision_checks),
            "weight_distribution": (self.config.run_weight_distribution, self._get_weight_distribution),
        }

        for name, (enabled, generator) in analysis_map.items():
            if enabled and name not in skip_analyses:
                script_parts.append(generator())

        script_parts.append(self._get_summary())
        script_parts.append(self._get_main())

        script = "\n\n".join(script_parts)

        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w") as f:
            f.write(script)

    def _get_header(self) -> str:
        """Get script header."""
        shapes_str = "\n".join([f"# - {k}: {v}" for k, v in self.config.input_shapes.items()])
        return f'''#!/usr/bin/env python3
"""
Module Initialization Analysis: {self.class_name}

Module: {self.module_identifier}
Input Shapes:
{shapes_str}
Device: {self.config.device}
Dtype: {self.config.dtype}

Generated by utilities.layer_analysis
"""'''

    def _get_imports(self) -> str:
        """Get import statements."""
        return '''import sys
import os
from pathlib import Path

# Add project root to path
project_root = Path(os.getcwd())
while not (project_root / "models").exists() and project_root.parent != project_root:
    project_root = project_root.parent
sys.path.insert(0, str(project_root))

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Any'''

    def _get_setup(self) -> str:
        """Get setup code."""
        cls = load_module_class(self.module_identifier)
        # Use primary input shape for default merging
        module_config_dict = merge_kwargs(
            cls, self.module_kwargs, self.config.input_shape
        )
        module_config_str = "{\n" + "\n".join(
            f"    {k!r}: {v!r}," for k, v in module_config_dict.items()
        ) + "\n}"
        loss_fn = self._get_loss_fn()
        input_shapes_str = json.dumps(self.config.input_shapes, indent=4)

        return f'''# === CONFIGURATION (modify these as needed) ===
INPUT_SHAPES = {input_shapes_str}
LOSS_FN = {loss_fn!r}
MODULE_CONFIG = {module_config_str}

# Derived configuration
DEVICE = torch.device("{self.config.device}" if torch.cuda.is_available() else "cpu")
DTYPE = torch.{self.config.dtype}

# Set random seed
torch.manual_seed(42)'''

    def _get_loss_fn(self) -> str:
        """Resolve the loss function name for gradient analysis.

        Returns
        -------
        str
            Loss function name.
        """
        loss_fn = self.config.gradient_loss_fn
        if isinstance(loss_fn, list):
            return loss_fn[0] if loss_fn else "reconstruction"
        return loss_fn

    def _get_loss_code(self, loss_fn: str) -> str:
        """Generate loss computation code for the specified loss function.

        Parameters
        ----------
        loss_fn : str
            Loss function name.

        Returns
        -------
        str
            Python code snippet that assigns `loss`.
        """
        if loss_fn == "sum":
            return "loss = out.sum()"
        if loss_fn == "mse_random":
            return "target = torch.randn_like(out)\nloss = F.mse_loss(out, target)"
        if loss_fn == "reconstruction":
            return (
                "loss = None\n"
                "for x in inputs.values():\n"
                "    if out.shape == x.shape:\n"
                "        loss = F.mse_loss(out, x)\n"
                "        break\n"
                "if loss is None:\n"
                "    loss = out.sum()  # Fallback"
            )
        if loss_fn == "variance":
            return "loss = -out.var()"
        return "loss = out.sum()  # fallback"

    def _get_module_instantiation(self) -> str:
        """Get module instantiation code."""
        return f'''# Import and instantiate module
from {self.module_path} import {self.class_name}


def create_module():
    """Create and configure the module for analysis."""
    module = {self.class_name}(**MODULE_CONFIG).to(device=DEVICE, dtype=DTYPE)
    module.eval()
    return module'''

    def _get_parameter_norms(self) -> str:
        """Get parameter norm analysis code."""
        return '''def analyze_parameter_norms(module: nn.Module) -> Dict[str, Dict[str, float]]:
    """Analyze parameter norms."""
    print("\n" + "=" * 60)
    print("PARAMETER NORM ANALYSIS")
    print("=" * 60)

    param_norms = {}
    for name, param in module.named_parameters():
        param_data = param.data.float()

        frobenius = torch.linalg.norm(param_data.flatten()).item()
        sup_norm = param_data.abs().max().item()
        std = param_data.std().item()

        if param_data.dim() >= 2:
            reshaped = param_data.reshape(param_data.size(0), -1)
            operator_norm = torch.linalg.matrix_norm(reshaped, ord=2).item()
        else:
            operator_norm = frobenius

        param_norms[name] = {
            "frobenius": frobenius,
            "operator": operator_norm,
            "sup": sup_norm,
            "std": std,
        }

        print(f"  {name}: frob={frobenius:.4f}, op={operator_norm:.4f}, sup={sup_norm:.4f}")

    return param_norms'''

    def _get_operator_norm(self) -> str:
        """Get operator norm estimation code."""
        return f'''def estimate_operator_norm(module: nn.Module, n_samples: int = 50) -> Dict[str, Dict[str, float]]:
    """Estimate effective operator norm."""
    print("\n" + "=" * 60)
    print("OPERATOR NORM ESTIMATION")
    print("=" * 60)

    estimates = {{}}

    for dist_name in ["normal", "sparse", "large_magnitude"]:
        ratios = []

        for _ in range(n_samples):
            inputs = {{}}
            total_input_norm_sq = 0.0

            for name, shape in INPUT_SHAPES.items():
                if dist_name == "normal":
                    x = torch.randn(*shape, device=DEVICE, dtype=DTYPE)
                elif dist_name == "sparse":
                    x = torch.randn(*shape, device=DEVICE, dtype=DTYPE)
                    x = x * (torch.rand_like(x) > 0.9)
                else:
                    x = torch.randn(*shape, device=DEVICE, dtype=DTYPE) * 100
                
                inputs[name] = x
                total_input_norm_sq += torch.linalg.norm(x.flatten())**2

            input_norm = torch.sqrt(torch.tensor(total_input_norm_sq))
            if input_norm < 1e-8:
                continue

            with torch.no_grad():
                out = module(**inputs)
                if isinstance(out, tuple):
                    out = out[0]
                y_norm = torch.linalg.norm(out.flatten())
                ratio = (y_norm / input_norm).item()
                if not np.isnan(ratio) and not np.isinf(ratio):
                    ratios.append(ratio)

        if ratios:
            estimates[dist_name] = {{"max": max(ratios), "mean": np.mean(ratios)}}
            print(f"  {{dist_name}}: max={{max(ratios):.4f}}, mean={{np.mean(ratios):.4f}}")

    return estimates'''

    def _get_gradient_analysis(self) -> str:
        """Get gradient analysis code."""
        loss_fn = self._get_loss_fn()
        loss_code = textwrap.indent(self._get_loss_code(loss_fn), "    ")
        return f'''def analyze_gradients(module: nn.Module) -> Dict[str, Dict[str, Any]]:
    """Analyze gradient existence and norms."""
    print("\n" + "=" * 60)
    print("GRADIENT ANALYSIS (loss: {loss_fn})")
    print("=" * 60)

    inputs = {{}}
    for name, shape in INPUT_SHAPES.items():
        inputs[name] = torch.randn(*shape, device=DEVICE, dtype=DTYPE, requires_grad=True)

    module.train()
    out = module(**inputs)
    if isinstance(out, tuple):
        out = out[0]

    # Compute loss ({loss_fn})
{loss_code}
    loss.backward()

    gradient_info = {{}}
    missing = 0

    for name, param in module.named_parameters():
        if param.grad is None:
            missing += 1
            gradient_info[name] = {{"has_grad": False}}
        else:
            norm = torch.linalg.norm(param.grad.flatten()).item()
            gradient_info[name] = {{"has_grad": True, "norm": norm}}
            print(f"  {{name}}: {{norm:.6f}}")

    if missing > 0:
        print(f"\nWARNING: {{missing}} parameters missing gradients!")
    else:
        print("\nAll parameters have gradients.")

    module.zero_grad()
    module.eval()
    return gradient_info'''

    def _get_spectral_analysis(self) -> str:
        """Get spectral analysis code."""
        return '''def analyze_spectral(module: nn.Module) -> Dict[str, Dict[str, float]]:
    """Analyze spectral properties of weight matrices."""
    print("\n" + "=" * 60)
    print("SPECTRAL ANALYSIS")
    print("=" * 60)

    spectral_info = {}

    for name, param in module.named_parameters():
        if param.dim() < 2:
            continue

        weight = param.data.float().reshape(param.size(0), -1)
        try:
            S = torch.linalg.svdvals(weight)
            spectral_info[name] = {
                "spectral_radius": S[0].item(),
                "condition_number": (S[0] / S[-1]).item() if S[-1] > 1e-10 else float("inf"),
            }
            print(f"  {name}: radius={{S[0].item():.4f}}, cond={{spectral_info[name]['condition_number']:.2f}}")
        except Exception as e:
            print(f"  {name}: SVD failed ({e})")

    return spectral_info'''

    def _get_rank_analysis(self) -> str:
        """Get rank analysis code."""
        return '''def analyze_rank(module: nn.Module) -> Dict[str, Dict[str, Any]]:
    """Analyze effective rank of weight matrices."""
    print("\n" + "=" * 60)
    print("RANK ANALYSIS")
    print("=" * 60)

    rank_info = {}

    for name, param in module.named_parameters():
        if param.dim() < 2:
            continue

        weight = param.data.float().reshape(param.size(0), -1)
        theoretical_max = min(weight.shape)
        S = torch.linalg.svdvals(weight)
        effective_rank = (S > 1e-6).sum().item()

        rank_info[name] = {
            "effective_rank": effective_rank,
            "theoretical_max": theoretical_max,
            "ratio": effective_rank / theoretical_max,
        }
        print(f"  {name}: {effective_rank}/{theoretical_max} ({effective_rank/theoretical_max:.1%})")

    return rank_info'''

    def _get_lipschitz(self) -> str:
        """Get Lipschitz estimation code."""
        return f'''def estimate_lipschitz(module: nn.Module, n_samples: int = 50) -> Dict[str, float]:
    """Estimate Lipschitz constant."""
    print("\n" + "=" * 60)
    print("LIPSCHITZ ESTIMATION")
    print("=" * 60)

    ratios = []

    for _ in range(n_samples):
        inputs = {{}}
        deltas = {{}}
        total_delta_norm_sq = 0.0

        for name, shape in INPUT_SHAPES.items():
            x = torch.randn(*shape, device=DEVICE, dtype=DTYPE)
            delta = torch.randn_like(x) * 0.01
            inputs[name] = x
            deltas[name] = delta
            total_delta_norm_sq += torch.linalg.norm(delta.flatten())**2
        
        inputs_perturbed = {{k: v + deltas[k] for k, v in inputs.items()}}

        with torch.no_grad():
            y1 = module(**inputs)
            y2 = module(**inputs_perturbed)
            if isinstance(y1, tuple):
                y1, y2 = y1[0], y2[0]

        input_diff = torch.sqrt(torch.tensor(total_delta_norm_sq))
        output_diff = torch.linalg.norm((y2 - y1).flatten()).item()

        if input_diff > 1e-10:
            ratios.append(output_diff / input_diff)

    result = {{"max": max(ratios), "mean": np.mean(ratios)}}
    print(f"  Empirical max: {{result['max']:.4f}}")
    print(f"  Empirical mean: {{result['mean']:.4f}}")
    return result'''

    def _get_activation_stats(self) -> str:
        """Get activation statistics code."""
        return f'''def analyze_activations(module: nn.Module) -> Dict[str, Dict[str, float]]:
    """Analyze activation statistics."""
    print("\n" + "=" * 60)
    print("ACTIVATION STATISTICS")
    print("=" * 60)

    stats = {{}}

    def make_hook(name):
        def hook(mod, inp, out):
            if isinstance(out, tuple):
                out = out[0]
            if isinstance(out, torch.Tensor):
                o = out.detach().float()
                stats[name] = {{"mean": o.mean().item(), "std": o.std().item(), "max": o.max().item()}}
        return hook

    hooks = []
    for name, layer in module.named_modules():
        if name:
            hooks.append(layer.register_forward_hook(make_hook(name)))

    with torch.no_grad():
        inputs = {{k: torch.randn(*s, device=DEVICE, dtype=DTYPE) for k, s in INPUT_SHAPES.items()}}
        module(**inputs)

    for hook in hooks:
        hook.remove()

    for name, s in list(stats.items())[:10]:
        print(f"  {{name}}: mean={{s['mean']:.4f}}, std={{s['std']:.4f}}")

    return stats'''

    def _get_gradient_ratios(self) -> str:
        """Get gradient ratio code."""
        loss_fn = self._get_loss_fn()
        loss_code = textwrap.indent(self._get_loss_code(loss_fn), "    ")
        return f'''def analyze_gradient_ratios(module: nn.Module) -> Dict[str, float]:
    """Analyze gradient ratios between layers."""
    print("\n" + "=" * 60)
    print("GRADIENT RATIOS (loss: {loss_fn})")
    print("=" * 60)

    module.train()
    module.zero_grad()

    inputs = {{}}
    for name, shape in INPUT_SHAPES.items():
        inputs[name] = torch.randn(*shape, device=DEVICE, dtype=DTYPE, requires_grad=True)

    out = module(**inputs)
    if isinstance(out, tuple):
        out = out[0]
    # Compute loss ({loss_fn})
{loss_code}
    loss.backward()

    layer_grads = {{}}
    for name, param in module.named_parameters():
        if param.grad is None:
            continue
        layer = name.split(".")[0]
        if layer not in layer_grads:
            layer_grads[layer] = []
        layer_grads[layer].append(torch.linalg.norm(param.grad.flatten()).item())

    layer_norms = {{l: np.sqrt(sum(n**2 for n in norms)) for l, norms in layer_grads.items()}}
    layers = list(layer_norms.keys())

    ratios = {{}}
    for i in range(len(layers) - 1):
        ratio = layer_norms[layers[i+1]] / (layer_norms[layers[i]] + 1e-10)
        ratios[f"{{layers[i]}}->{{layers[i+1]}}"] = ratio
        print(f"  {{layers[i]}} -> {{layers[i+1]}}: {{ratio:.4f}}")

    module.zero_grad()
    module.eval()
    return ratios'''

    def _get_precision_checks(self) -> str:
        """Get precision check code."""
        return f'''def check_precision(module: nn.Module) -> Dict[str, bool]:
    """Check for numerical precision issues."""
    print("\n" + "=" * 60)
    print("PRECISION CHECKS")
    print("=" * 60)

    issues = []

    for name, param in module.named_parameters():
        p = param.data.float()
        if torch.isnan(p).any():
            issues.append(f"{{name}}: NaN")
        if torch.isinf(p).any():
            issues.append(f"{{name}}: Inf")

    with torch.no_grad():
        inputs = {{k: torch.randn(*s, device=DEVICE, dtype=DTYPE) for k, s in INPUT_SHAPES.items()}}
        out = module(**inputs)
        if isinstance(out, tuple):
            out = out[0]
        if torch.isnan(out).any():
            issues.append("Output: NaN")
        if torch.isinf(out).any():
            issues.append("Output: Inf")

    if issues:
        for issue in issues:
            print(f"  WARNING: {{issue}}")
    else:
        print("  All checks passed.")

    return {{"passed": len(issues) == 0, "issues": issues}}'''

    def _get_weight_distribution(self) -> str:
        """Get weight distribution code."""
        return '''def analyze_weight_distribution(module: nn.Module, save_plot: bool = True):
    """Analyze and visualize weight distributions."""
    print("\n" + "=" * 60)
    print("WEIGHT DISTRIBUTIONS")
    print("=" * 60)

    for name, param in module.named_parameters():
        w = param.data.float().flatten()
        print(f"  {name}: mean={{w.mean().item():.4f}}, std={{w.std().item():.4f}}")

    if save_plot:
        params = [(n, p) for n, p in module.named_parameters() if p.dim() >= 2][:4]
        if params:
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            for ax, (name, param) in zip(axes.flatten(), params):
                values = param.data.cpu().float().flatten().numpy()
                ax.hist(values, bins=50, density=True, alpha=0.7)
                ax.axvline(values.mean(), color="r", linestyle="--")
                ax.set_title(name.split(".")[-1][:20])
            plt.tight_layout()
            plt.savefig("weight_distributions.png", dpi=150)
            print("\n  Plot saved to weight_distributions.png")'''

    def _get_summary(self) -> str:
        """Get summary code."""
        return '''def print_summary(results: Dict[str, Any]):
    """Print analysis summary."""
    print("\n" + "=" * 60)
    print("SUMMARY")
    print("=" * 60)
    print(f"Analysis complete. Check output above for details.")'''

    def _get_main(self) -> str:
        """Get main function."""
        return '''if __name__ == "__main__":
    print("Module Initialization Analysis")
    print("=" * 60)

    # Create module
    module = create_module()
    print(f"Module: {type(module).__name__}")
    print(f"Parameters: {sum(p.numel() for p in module.parameters()):,}")

    # Run analyses
    results = {}
    results["param_norms"] = analyze_parameter_norms(module)
    results["operator_norm"] = estimate_operator_norm(module)
    results["gradients"] = analyze_gradients(module)
    results["spectral"] = analyze_spectral(module)
    results["rank"] = analyze_rank(module)
    results["lipschitz"] = estimate_lipschitz(module)
    results["activations"] = analyze_activations(module)
    results["grad_ratios"] = analyze_gradient_ratios(module)
    results["precision"] = check_precision(module)
    analyze_weight_distribution(module)

    print_summary(results)'''